{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression techniques for speaker characterization\n",
    "### Laura Fernández Gallardo\n",
    "\n",
    "Multioutput regression of the 7 items contributing to the [perception](https://github.com/laufergall/Subjective_Speaker_Characteristics) of the 'warmth' trait:\n",
    "\n",
    "warmth (males) = \n",
    "0.85 x hearty + 0.84 x affectionate - 0.76 x distant + 0.59 x friendly - 0.58 x unsympathetic - 0.52 x non_likable + 0.51 x not_irritated \n",
    "\n",
    "warmth (females) = \n",
    "0.84 x hearty + 0.84 x affectionate - 0.78 x distant + 0.56 x friendly - 0.49 x unsympathetic + 0.49 x not_irritated - 0.45 x non_likable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from reg_tuning import * # my helper functions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 2302\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/'\n",
    "\n",
    "url = path + \"feats_ratings_scores_train.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_train = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"feats_ratings_scores_test.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_test = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "with open(r'..\\data\\generated_data\\feats_names.txt') as f:\n",
    "    feats_names = f.readlines()\n",
    "feats_names = [x.strip().strip('\\'') for x in feats_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\items_names.txt') as f:\n",
    "    items_names = f.readlines()\n",
    "items_names = [x.strip().strip('\\'') for x in items_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\traits_names.txt') as f:\n",
    "    traits_names = f.readlines()\n",
    "traits_names = [x.strip().strip('\\'') for x in traits_names] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7warmthitems: Model tuning\n",
    "\n",
    "Use the train data to find the regressor and its hyperparameters leading to the best performance. \n",
    "\n",
    "Not performing feature selection with \"SelectKBest\": Univariate feature selection does not support multilabel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize speech features  \n",
    "\n",
    "dropcolumns = ['name','spkID','speaker_gender'] + items_names + traits_names\n",
    "\n",
    "# learn transformation on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feats_ratings_scores_train.drop(dropcolumns, axis=1))\n",
    "\n",
    "# numpy n_instances x n_feats\n",
    "feats_s_train = scaler.transform(feats_ratings_scores_train.drop(dropcolumns, axis=1))\n",
    "feats_s_test = scaler.transform(feats_ratings_scores_test.drop(dropcolumns, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warmthitems_names = ['hearty','affectionate','distant','friendly','unsympathetic','non_likable','not_irritated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training data. Features and labels\n",
    "X = feats_s_train # (2700, 88)\n",
    "y = feats_ratings_scores_train[warmthitems_names].as_matrix() # (2700, 7)\n",
    "\n",
    "# test data. Features and labels\n",
    "Xt = feats_s_test # (891, 88)\n",
    "yt = feats_ratings_scores_test[warmthitems_names].as_matrix() # (891, 7)\n",
    "\n",
    "# split train data into 80% and 20% subsets - with balance in trait and gender\n",
    "# give subset A to the inner hyperparameter tuner\n",
    "# and hold out subset B for meta-evaluation\n",
    "AX, BX, Ay, By = train_test_split(X, y, \n",
    "                                  test_size=0.20, \n",
    "                                  stratify = feats_ratings_scores_train['speaker_gender'], \n",
    "                                  random_state=2302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe with results from hp tuner to be appended\n",
    "tuning_all = pd.DataFrame()\n",
    "\n",
    "# list with tuned models trained on training data, to be appended\n",
    "trained_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save splits\n",
    "\n",
    "label = 'multioutput_7warmthitems'\n",
    "\n",
    "# train/test partitions, features and labels\n",
    "np.save(r'.\\data_while_tuning\\X_' + label + '.npy', X)\n",
    "np.save(r'.\\data_while_tuning\\y_' + label + '.npy', y)\n",
    "np.save(r'.\\data_while_tuning\\Xt_' + label + '.npy', Xt)\n",
    "np.save(r'.\\data_while_tuning\\yt_' + label + '.npy', yt)\n",
    "\n",
    "# # A/B splits, features and labels\n",
    "np.save(r'.\\data_while_tuning\\AX_' + label + '.npy', AX)\n",
    "np.save(r'.\\data_while_tuning\\BX_' + label + '.npy', BX)\n",
    "np.save(r'.\\data_while_tuning\\Ay_' + label + '.npy', Ay)\n",
    "np.save(r'.\\data_while_tuning\\By_' + label + '.npy', By)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling hp_tuner() for each regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recover ** when new ipynb session started.\n",
    "\n",
    "(Workaround for working with hyperparameter tuning during several days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label = 'multioutput_7warmthitems'\n",
    "\n",
    "# # train/test partitions, features and labels\n",
    "# X = np.load(r'.\\data_while_tuning\\X_' + label + '.npy')\n",
    "# y = np.load(r'.\\data_while_tuning\\y_' + label + '.npy')\n",
    "# Xt = np.load(r'.\\data_while_tuning\\Xt_' + label + '.npy')\n",
    "# yt = np.load(r'.\\data_while_tuning\\yt_' + label + '.npy')\n",
    "\n",
    "# # A/B splits, features and labels\n",
    "# AX = np.load(r'.\\data_while_tuning\\AX_' + label + '.npy')\n",
    "# BX = np.load(r'.\\data_while_tuning\\BX_' + label + '.npy')\n",
    "# Ay = np.load(r'.\\data_while_tuning\\Ay_' + label + '.npy')\n",
    "# By = np.load(r'.\\data_while_tuning\\By_' + label + '.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Loading outpus of hp tuning from disk\n",
    "# tuning_all, trained_all = load_tuning(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this after each experiment **to recover later**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # save tuning_all (.csv) and trained_all (namemodel.sav)\n",
    "# save_tuning(tuning_all, trained_all, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "*class sklearn.ensemble.RandomForestRegressor(n_estimators=10, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)*\n",
    "\n",
    "Tune: max_features, max_depth, min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RandomForestRegressor' -> Best cross-val score on A set: -55.505871 using {'regressor__estimator__min_samples_leaf': 2, 'regressor__estimator__max_features': 40, 'regressor__estimator__max_depth': 22}\n",
      "'RandomForestRegressor' -> root mean_squared_error on B set: 7.221159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\"\"\"\n",
    "Random Forest\n",
    "\"\"\"\n",
    "def get_RandomForestRegressor2tune():\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=2302, max_features = None)\n",
    "    hp = dict(\n",
    "        regressor__estimator__max_features = np.arange(2,50),\n",
    "        regressor__estimator__max_depth = np.arange(2,50), \n",
    "        regressor__estimator__min_samples_leaf = np.arange(2,50) \n",
    "    )\n",
    "    return 'RandomForestRegressor', model, hp\n",
    "\n",
    "# tune this model (multiputput)\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, \n",
    "                           [get_RandomForestRegressor2tune], \n",
    "                           label,\n",
    "                           feats_names,\n",
    "                           [88], # feature selection not performed\n",
    "                           mode='random',\n",
    "                           n_iter=50\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RandomForestRegressor' -> Best cross-val score on A set: -55.330047 using {'regressor__estimator__min_samples_leaf': 2, 'regressor__estimator__max_features': 32, 'regressor__estimator__max_depth': 26}\n",
      "'RandomForestRegressor' -> root mean_squared_error on B set: 7.132426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\"\"\"\n",
    "Random Forest\n",
    "\"\"\"\n",
    "def get_RandomForestRegressor2tune():\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=2302, max_features = None)\n",
    "    hp = dict(\n",
    "        regressor__estimator__max_features = np.arange(30,50),\n",
    "        regressor__estimator__max_depth = np.arange(15,35), \n",
    "        regressor__estimator__min_samples_leaf = np.arange(2,5) \n",
    "    )\n",
    "    return 'RandomForestRegressor', model, hp\n",
    "\n",
    "# tune this model (multiputput)\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, \n",
    "                           [get_RandomForestRegressor2tune], \n",
    "                           label,\n",
    "                           feats_names,\n",
    "                           [88], # feature selection not performed\n",
    "                           mode='random',\n",
    "                           n_iter=50\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update lists of tuning info and trained regressors\n",
    "tuning_all = tuning_all.append(tuning, ignore_index=True)\n",
    "trained_all.append(trained)\n",
    "\n",
    "# save tuning_all (.csv) and trained_all (nameregressor.sav)\n",
    "save_tuning(tuning_all, trained_all, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree\n",
    "\n",
    "*class sklearn.tree.DecisionTreeRegressor(criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort=False)*\n",
    "\n",
    "Tune: max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DecisionTreeRegressor' -> Best cross-val score on A set: -78.252017 using {'regressor__estimator__max_features': 30, 'regressor__estimator__max_depth': 4}\n",
      "'DecisionTreeRegressor' -> root mean_squared_error on B set: 8.468760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\"\"\"\n",
    "Decision Trees\n",
    "\"\"\"\n",
    "def get_DecisionTreeRegressor2tune():\n",
    "    \n",
    "    model = DecisionTreeRegressor()\n",
    "    hp = dict(\n",
    "        regressor__estimator__max_depth = np.arange(2,30), \n",
    "        regressor__estimator__max_features = np.arange(2,50)\n",
    "    )\n",
    "    return 'DecisionTreeRegressor', model, hp\n",
    "\n",
    "# tune this model (multiputput)\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, \n",
    "                           [get_DecisionTreeRegressor2tune], \n",
    "                           label,\n",
    "                           feats_names,\n",
    "                           [88], # feature selection not performed\n",
    "                           mode='random',\n",
    "                           n_iter=30\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DecisionTreeRegressor' -> Best cross-val score on A set: -76.493110 using {'regressor__estimator__max_features': 39, 'regressor__estimator__max_depth': 4}\n",
      "'DecisionTreeRegressor' -> root mean_squared_error on B set: 8.460729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\"\"\"\n",
    "Decision Trees\n",
    "\"\"\"\n",
    "def get_DecisionTreeRegressor2tune():\n",
    "    \n",
    "    model = DecisionTreeRegressor()\n",
    "    hp = dict(\n",
    "        regressor__estimator__max_depth = np.arange(2,6), \n",
    "        regressor__estimator__max_features = np.arange(20,40)\n",
    "    )\n",
    "    return 'DecisionTreeRegressor', model, hp\n",
    "\n",
    "# tune this model (multiputput)\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, \n",
    "                           [get_DecisionTreeRegressor2tune], \n",
    "                           label,\n",
    "                           feats_names,\n",
    "                           [88], # feature selection not performed\n",
    "                           mode='random',\n",
    "                           n_iter=30\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update lists of tuning info and trained regressors\n",
    "tuning_all = tuning_all.append(tuning, ignore_index=True)\n",
    "trained_all.append(trained)\n",
    "\n",
    "# save tuning_all (.csv) and trained_all (nameregressor.sav)\n",
    "save_tuning(tuning_all, trained_all, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "model = DummyRegressor(strategy='mean')\n",
    "model.fit(AX, Ay)\n",
    "By_pred = model.predict(BX)\n",
    "score_on_B = np.sqrt(mean_squared_error(By, By_pred))\n",
    "d = {\n",
    "    'regressors_names': ['DummyRegressor'],\n",
    "    'best_accs': score_on_B,\n",
    "    'best_hps': '',\n",
    "    'sel_feats': '',\n",
    "    'sel_feats_i': ''\n",
    "    }\n",
    "\n",
    "tuning = pd.DataFrame(data = d)\n",
    "trained = model.fit(X, y)\n",
    "\n",
    "# update lists of tuning info and trained regressors\n",
    "tuning_all = tuning_all.append(tuning, ignore_index=True)\n",
    "trained_all.append([trained])\n",
    "\n",
    "# save tuning_all (.csv) and trained_all (nameregressor.sav)\n",
    "save_tuning(tuning_all, trained_all, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "### RMSE\n",
    "Testing the best model found after hyperparameter tuning.\n",
    "\n",
    "Performance metric: RMSE.\n",
    "    \n",
    "The predictions correspond to the scores of each test segment (3 parts x 4 dialogs) spoken by the same test speaker. I perform the average of the predicted scores that correspond to the same speaker - to be compared to the true scores.\n",
    "\n",
    "Visualization: pairplot of scores of true and predicted test data, grouped-averaged by speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data if new ipynb session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_accs</th>\n",
       "      <th>best_hps</th>\n",
       "      <th>regressors_names</th>\n",
       "      <th>sel_feats</th>\n",
       "      <th>sel_feats_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.132426</td>\n",
       "      <td>{'regressor__estimator__min_samples_leaf': 2, ...</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semit...</td>\n",
       "      <td>[ True  True  True  True  True  True  True  Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.460729</td>\n",
       "      <td>{'regressor__estimator__max_features': 39, 're...</td>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semit...</td>\n",
       "      <td>[ True  True  True  True  True  True  True  Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.933428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DummyRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_accs                                           best_hps  \\\n",
       "0   7.132426  {'regressor__estimator__min_samples_leaf': 2, ...   \n",
       "1   8.460729  {'regressor__estimator__max_features': 39, 're...   \n",
       "2   8.933428                                                NaN   \n",
       "\n",
       "        regressors_names                                          sel_feats  \\\n",
       "0  RandomForestRegressor  ['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semit...   \n",
       "1  DecisionTreeRegressor  ['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semit...   \n",
       "2         DummyRegressor                                                NaN   \n",
       "\n",
       "                                         sel_feats_i  \n",
       "0  [ True  True  True  True  True  True  True  Tr...  \n",
       "1  [ True  True  True  True  True  True  True  Tr...  \n",
       "2                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'multioutput_7warmthitems'\n",
    "\n",
    "\n",
    "path = 'https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/'\n",
    "\n",
    "url = path + \"feats_ratings_scores_train.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_train = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"feats_ratings_scores_test.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_test = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "with open(r'..\\data\\generated_data\\feats_names.txt') as f:\n",
    "    feats_names = f.readlines()\n",
    "feats_names = [x.strip().strip('\\'') for x in feats_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\items_names.txt') as f:\n",
    "    items_names = f.readlines()\n",
    "items_names = [x.strip().strip('\\'') for x in items_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\traits_names.txt') as f:\n",
    "    traits_names = f.readlines()\n",
    "traits_names = [x.strip().strip('\\'') for x in traits_names] \n",
    "\n",
    "# train/test partitions, features and labels\n",
    "X = np.load(r'.\\data_while_tuning\\X_' + label + '.npy')\n",
    "y = np.load(r'.\\data_while_tuning\\y_' + label + '.npy')\n",
    "Xt = np.load(r'.\\data_while_tuning\\Xt_' + label + '.npy')\n",
    "yt = np.load(r'.\\data_while_tuning\\yt_' + label + '.npy')\n",
    "\n",
    "# Loading outpus of hp tuning from disk\n",
    "tuning_all, trained_all = load_tuning(label)\n",
    "tuning_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warmthitems_names = ['hearty','affectionate','distant','friendly','unsympathetic','non_likable','not_irritated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classifier based on the best performance on B: 'RandomForestRegressor' (perf. on B = 7.13)\n"
     ]
    }
   ],
   "source": [
    "# select the classifier that gave the maximum acc on B set\n",
    "best_accs = tuning_all['best_accs']\n",
    "i_best = best_accs.idxmin()\n",
    "\n",
    "print('Selected classifier based on the best performance on B: %r (perf. on B = %0.2f)' % (tuning_all.loc[i_best,'regressors_names'], round(best_accs[i_best],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RandomForestRegressor' -> avg RMSE 'hearty' = 9.67\n",
      "'RandomForestRegressor' -> avg R2 'hearty' = 0.20\n",
      "'RandomForestRegressor' -> avg RMSE 'affectionate' = 9.23\n",
      "'RandomForestRegressor' -> avg R2 'affectionate' = 0.23\n",
      "'RandomForestRegressor' -> avg RMSE 'distant' = 9.25\n",
      "'RandomForestRegressor' -> avg R2 'distant' = 0.15\n",
      "'RandomForestRegressor' -> avg RMSE 'friendly' = 8.57\n",
      "'RandomForestRegressor' -> avg R2 'friendly' = 0.22\n",
      "'RandomForestRegressor' -> avg RMSE 'unsympathetic' = 7.32\n",
      "'RandomForestRegressor' -> avg R2 'unsympathetic' = 0.11\n",
      "'RandomForestRegressor' -> avg RMSE 'non_likable' = 10.17\n",
      "'RandomForestRegressor' -> avg R2 'non_likable' = 0.09\n",
      "'RandomForestRegressor' -> avg RMSE 'not_irritated' = 9.57\n",
      "'RandomForestRegressor' -> avg R2 'not_irritated' = 0.06\n",
      "'RandomForestRegressor' -> avg R2 overall: 0.15\n",
      "\n",
      "'DecisionTreeRegressor' -> avg RMSE 'hearty' = 9.67\n",
      "'DecisionTreeRegressor' -> avg R2 'hearty' = 0.20\n",
      "'DecisionTreeRegressor' -> avg RMSE 'affectionate' = 9.65\n",
      "'DecisionTreeRegressor' -> avg R2 'affectionate' = 0.16\n",
      "'DecisionTreeRegressor' -> avg RMSE 'distant' = 9.62\n",
      "'DecisionTreeRegressor' -> avg R2 'distant' = 0.08\n",
      "'DecisionTreeRegressor' -> avg RMSE 'friendly' = 9.14\n",
      "'DecisionTreeRegressor' -> avg R2 'friendly' = 0.11\n",
      "'DecisionTreeRegressor' -> avg RMSE 'unsympathetic' = 7.62\n",
      "'DecisionTreeRegressor' -> avg R2 'unsympathetic' = 0.03\n",
      "'DecisionTreeRegressor' -> avg RMSE 'non_likable' = 10.27\n",
      "'DecisionTreeRegressor' -> avg R2 'non_likable' = 0.07\n",
      "'DecisionTreeRegressor' -> avg RMSE 'not_irritated' = 10.00\n",
      "'DecisionTreeRegressor' -> avg R2 'not_irritated' = -0.03\n",
      "'DecisionTreeRegressor' -> avg R2 overall: 0.09\n",
      "\n",
      "'DummyRegressor' -> avg RMSE 'hearty' = 10.81\n",
      "'DummyRegressor' -> avg R2 'hearty' = -0.00\n",
      "'DummyRegressor' -> avg RMSE 'affectionate' = 10.50\n",
      "'DummyRegressor' -> avg R2 'affectionate' = -0.00\n",
      "'DummyRegressor' -> avg RMSE 'distant' = 10.10\n",
      "'DummyRegressor' -> avg R2 'distant' = -0.01\n",
      "'DummyRegressor' -> avg RMSE 'friendly' = 9.69\n",
      "'DummyRegressor' -> avg R2 'friendly' = -0.00\n",
      "'DummyRegressor' -> avg RMSE 'unsympathetic' = 7.79\n",
      "'DummyRegressor' -> avg R2 'unsympathetic' = -0.01\n",
      "'DummyRegressor' -> avg RMSE 'non_likable' = 10.68\n",
      "'DummyRegressor' -> avg R2 'non_likable' = -0.00\n",
      "'DummyRegressor' -> avg RMSE 'not_irritated' = 9.88\n",
      "'DummyRegressor' -> avg R2 'not_irritated' = -0.00\n",
      "'DummyRegressor' -> avg R2 overall: -0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# go through performace for all regressors\n",
    "\n",
    "# removing duplicates from tuning_all (same classifier tuned twice with different searchers)\n",
    "indexes = tuning_all['regressors_names'].drop_duplicates(keep='last').index.values\n",
    "\n",
    "# dataframe for summary of performances\n",
    "# performances = pd.DataFrame(tuning_all.loc[indexes,['regressors_names','best_accs']])\n",
    "\n",
    "for i in indexes:\n",
    "\n",
    "    # compute predictions with the best tuned regressor\n",
    "\n",
    "    yt_pred = trained_all[i][0].predict(Xt)\n",
    "\n",
    "    # average of outputs that belong to the same speaker\n",
    "\n",
    "    true_scores = pd.DataFrame(data = feats_ratings_scores_test[warmthitems_names+['spkID']])\n",
    "    true_scores['type']='true'\n",
    "\n",
    "    pred_scores=pd.DataFrame()\n",
    "    for t in np.arange(0,len(warmthitems_names)):\n",
    "        pred_scores[warmthitems_names[t]] = yt_pred[:, t] \n",
    "    pred_scores['spkID'] = feats_ratings_scores_test['spkID']\n",
    "\n",
    "\n",
    "    # group by speakers and average\n",
    "    true_scores_avg = true_scores.groupby('spkID').mean()\n",
    "\n",
    "    pred_scores_avg = pred_scores.groupby('spkID').mean()\n",
    "\n",
    "\n",
    "    # RMSE and R2 for each trait separately\n",
    "    for t in np.arange(0,len(warmthitems_names)):\n",
    "        print('%r -> avg RMSE %r = %.2f' % (tuning_all.loc[i,'regressors_names'],\n",
    "                                      warmthitems_names[t], \n",
    "                                      np.sqrt(mean_squared_error(true_scores_avg[warmthitems_names[t]].as_matrix(), \n",
    "                                                                                  pred_scores_avg[warmthitems_names[t]].as_matrix()))\n",
    "                                     )\n",
    "             )\n",
    "        \n",
    "        print('%r -> avg R2 %r = %.2f' % (tuning_all.loc[i,'regressors_names'],\n",
    "                                      warmthitems_names[t], \n",
    "                                      r2_score(true_scores_avg[warmthitems_names[t]].as_matrix(), \n",
    "                                                                                  pred_scores_avg[warmthitems_names[t]].as_matrix())\n",
    "                                     )\n",
    "             )\n",
    "\n",
    "    # overall RMSE and R2\n",
    "    myrmse_avg = np.sqrt(mean_squared_error(true_scores_avg[warmthitems_names].as_matrix(), \n",
    "                                            pred_scores_avg[warmthitems_names].as_matrix())\n",
    "                        )\n",
    "    myr2_avg = r2_score(true_scores_avg[warmthitems_names].as_matrix(), \n",
    "                                            pred_scores_avg[warmthitems_names].as_matrix()\n",
    "                        )\n",
    "    print('%r -> avg R2 overall: %0.2f' % (tuning_all.loc[i,'regressors_names'], myr2_avg))\n",
    "    print('')\n",
    "    \n",
    "        \n",
    "    # append true and predicted scores\n",
    "\n",
    "    true_scores_avg.reset_index(inplace=True)\n",
    "    pred_scores_avg.reset_index(inplace=True) \n",
    "\n",
    "    true_scores_avg['type']='true'\n",
    "    pred_scores_avg['type']='pred'\n",
    "\n",
    "    test_scores_avg=true_scores_avg.append(pred_scores_avg)\n",
    "\n",
    "#     # pairplot color-coded by true/predicted test data\n",
    "#     myfig = sns.pairplot(test_scores_avg.drop('spkID', axis=1), hue='type')\n",
    "\n",
    "#     # save figure\n",
    "#     filename = label + '_test_'+tuning_all.loc[i,'regressors_names']+'.png'\n",
    "#     myfig.savefig('.\\\\figures\\\\' + filename, bbox_inches = 'tight')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are more or less the same results as when doing multioutput classification with the 34 items."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
