{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression techniques for speaker characterization\n",
    "### Laura FernÃ¡ndez Gallardo\n",
    "\n",
    "Train (tune) and test with SVRrbf all traits individually: 'warmth', 'attractiveness', 'compliance', 'confidence', 'maturity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import time # for timestamps\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval # parsing hp after tuner\n",
    "\n",
    "from reg_tuning import * # my helper functions\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 2302\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/'\n",
    "\n",
    "url = path + \"feats_ratings_scores_train.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_train = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"feats_ratings_scores_test.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_test = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "with open(r'..\\data\\generated_data\\feats_names.txt') as f:\n",
    "    feats_names = f.readlines()\n",
    "feats_names = [x.strip().strip('\\'') for x in feats_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\items_names.txt') as f:\n",
    "    items_names = f.readlines()\n",
    "items_names = [x.strip().strip('\\'') for x in items_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\traits_names.txt') as f:\n",
    "    traits_names = f.readlines()\n",
    "traits_names = [x.strip().strip('\\'') for x in traits_names] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning with feature selection\n",
    "\n",
    "Model: SVR with rbf kernel (worked well for the regression of 'warmth').\n",
    "\n",
    "Nested hyperparameter tuning with feature selection.\n",
    "\n",
    "* Feature selection: SelectKBest(f_regression), tuning k\n",
    "* RandomizedSearchCV on hyperparameters with uniform distribution.\n",
    "* metric: neg_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize speech features  \n",
    "\n",
    "dropcolumns = ['name','spkID','speaker_gender'] + items_names + traits_names\n",
    "\n",
    "# learn transformation on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feats_ratings_scores_train.drop(dropcolumns, axis=1))\n",
    "\n",
    "# numpy n_instances x n_feats\n",
    "feats_s_train = scaler.transform(feats_ratings_scores_train.drop(dropcolumns, axis=1))\n",
    "feats_s_test = scaler.transform(feats_ratings_scores_test.drop(dropcolumns, axis=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of helper functions (copied from Part 02)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_B_partitions(target_trait):\n",
    "    \n",
    "    X = feats_s_train # (2700, 88)\n",
    "    y = feats_ratings_scores_train[target_trait].as_matrix() # (2700,)\n",
    "\n",
    "    Xt = feats_s_test # (891, 88)\n",
    "    yt = feats_ratings_scores_test[target_trait].as_matrix() # (891,)\n",
    "\n",
    "    # split train data into 80% and 20% subsets - with balance in gender\n",
    "    # give subset A to the inner hyperparameter tuner\n",
    "    # and hold out subset B for meta-evaluation\n",
    "    return train_test_split(X, y, test_size=0.20, stratify = feats_ratings_scores_train['speaker_gender'], random_state=2302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\"\"\"\n",
    "Support Vector Machines with rbf kernel\n",
    "\"\"\"\n",
    "def get_SVRrbf2tune():\n",
    "    \n",
    "    model = SVR()\n",
    "    hp = dict(\n",
    "        regressor__C = np.logspace(1,3,num=3),\n",
    "        regressor__kernel = ['rbf'], \n",
    "        regressor__gamma = np.logspace(-3,-1,num=3)\n",
    "    )\n",
    "    return 'SVRrbf', model, hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "def trainDummyRegressor(AX, BX, Ay, By):\n",
    "\n",
    "    model = DummyRegressor(strategy='mean')\n",
    "    model.fit(AX, Ay)\n",
    "    By_pred = model.predict(BX)\n",
    "    score_on_B = np.sqrt(mean_squared_error(By, By_pred))\n",
    "    d = {\n",
    "        'regressors_names': ['DummyRegressor'],\n",
    "        'best_accs': score_on_B,\n",
    "        'best_hps': '',\n",
    "        'sel_feats': '',\n",
    "        'sel_feats_i': ''\n",
    "        }\n",
    "\n",
    "    tuning = pd.DataFrame(data = d)\n",
    "    trained = model.fit(X, y)\n",
    "\n",
    "    return tuning, [trained]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_RMSE(tuning_all, trained_all):\n",
    "    # go through performace for all regressors\n",
    "\n",
    "    # removing duplicates from tuning_all (same classifier tuned twice with different searchers)\n",
    "    indexes = tuning_all['regressors_names'].drop_duplicates(keep='last').index.values\n",
    "\n",
    "    # dataframe for summary of performances\n",
    "    # performances = pd.DataFrame(tuning_all.loc[indexes,['regressors_names','best_accs']])\n",
    "\n",
    "    for i in indexes:\n",
    "\n",
    "        yt_pred = trained_all[i][0].predict(Xt)\n",
    "\n",
    "        # average of outputs that belong to the same speaker\n",
    "\n",
    "        test_scores = pd.DataFrame(data = feats_ratings_scores_test[[target_trait,'spkID']])\n",
    "        test_scores['pred'] = yt_pred\n",
    "\n",
    "        test_scores_avg = test_scores.groupby('spkID').mean()\n",
    "\n",
    "        myrmse = np.sqrt(mean_squared_error(test_scores[target_trait].as_matrix(), \n",
    "                     test_scores['pred'].as_matrix()))\n",
    "\n",
    "        myrmse_avg = np.sqrt(mean_squared_error(test_scores_avg[target_trait].as_matrix(), \n",
    "                     test_scores_avg['pred'].as_matrix()))\n",
    "\n",
    "        print('\"%r -> RMSE per instance on B: %0.2f' % (tuning_all.loc[i,'regressors_names'], tuning_all.loc[i,'best_accs']))   \n",
    "        print('\"%r -> RMSE per instance: %0.2f' % (tuning_all.loc[i,'regressors_names'], myrmse))   \n",
    "        print('\"%r -> RMSE after averaging over speaker utterances: %0.2f' % (tuning_all.loc[i,'regressors_names'], myrmse_avg))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for target_trait in traits_names:\n",
    "    \n",
    "    AX, BX, Ay, By = A_B_partitions(target_trait)\n",
    "    \n",
    "    # tune and train SVR with rbf kernel\n",
    "    tuning_svr, trained_svr = hp_tuner(AX, BX, Ay, By, \n",
    "                               [get_SVRrbf2tune], \n",
    "                               target_trait,\n",
    "                               feats_names,\n",
    "                               np.arange(50, AX.shape[1]+1), # selectKBest\n",
    "                               'random',\n",
    "                               n_iter=20\n",
    "                              )\n",
    "    tuning_all = tuning_all.append(tuning_svr, ignore_index=True)\n",
    "    trained_all.append(trained_svr)\n",
    "    \n",
    "    # \"train\" dummy regressor\n",
    "    tuning_dummy, trained_dummy = trainDummyRegressor(AX, BX, Ay, By)\n",
    "    tuning_all = tuning_all.append(tuning_dummy, ignore_index=True)\n",
    "    trained_all.append(trained_dummy)\n",
    "    \n",
    "    test_RMSE(tuning_all, trained_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
