{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression techniques for speaker characterization\n",
    "### Laura Fernández Gallardo\n",
    "\n",
    "Similarly as done for classification, the performances of different regression techniques for characterizing users by their voices are assessed in this notebook.\n",
    "\n",
    "I am addressing the prediction of each of the 34 interpersonal speaker [characteristics](https://github.com/laufergall/Subjective_Speaker_Characteristics) (continuous numeric labels of the [NSC corpus](http://www.qu.tu-berlin.de/?id=nsc-corpus)). These characteristics are: \n",
    "\n",
    "'non_likable', 'secure', 'attractive', 'unsympathetic', 'indecisive', 'unobtrusive', 'distant', 'bored', 'emotional', 'not_irritated', 'active', 'pleasant', 'characterless', 'sociable', 'relaxed', 'affectionate', 'dominant', 'unaffected', 'hearty', 'old', 'personal', 'calm', 'incompetent', 'ugly', 'friendly', 'masculine', 'submissive', 'indifferent', 'interesting', 'cynical', 'artificial', 'intelligent', 'childish', 'modest'.\n",
    "\n",
    "I will consider the common RMSE (root mean squared error) and the more robust to outliers MAPE (median absolute percentage error) as the metrics for success:\n",
    "\n",
    "\\begin{equation}\n",
    "RMSE = \\sqrt{\\frac{\\sum_i(y_i-\\hat{y}_i)^2}{n}}  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "MAPE = median(\\left | \\frac{y_i-\\hat{y}_i}{y_i} \\right |)\n",
    "\\end{equation}\n",
    "\n",
    "where $y_i$ and $\\hat{y_i}$ are the observed and the predicted values for the $i^{th}$ data point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import time # for timestamps\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from reg_tuning import * # my helper functions\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 2302\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker characteristics \n",
    "\n",
    "The files \"SC_ratings_medians.csv\" and \"SC_ratings_medians.csv\" have been generated in the ..\\data folder.\n",
    "\n",
    "We consider the same train/test partition of speakers as done for the WAAT classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_ID</th>\n",
       "      <th>speaker_gender</th>\n",
       "      <th>non_likable</th>\n",
       "      <th>secure</th>\n",
       "      <th>attractive</th>\n",
       "      <th>unsympathetic</th>\n",
       "      <th>indecisive</th>\n",
       "      <th>unobtrusive</th>\n",
       "      <th>distant</th>\n",
       "      <th>bored</th>\n",
       "      <th>...</th>\n",
       "      <th>friendly</th>\n",
       "      <th>masculine</th>\n",
       "      <th>submissive</th>\n",
       "      <th>indifferent</th>\n",
       "      <th>interesting</th>\n",
       "      <th>cynical</th>\n",
       "      <th>artificial</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>childish</th>\n",
       "      <th>modest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>36.571429</td>\n",
       "      <td>65.214286</td>\n",
       "      <td>59.785714</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>33.714286</td>\n",
       "      <td>66.857143</td>\n",
       "      <td>35.642857</td>\n",
       "      <td>35.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>75.428571</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>34.571429</td>\n",
       "      <td>60.571429</td>\n",
       "      <td>43.071429</td>\n",
       "      <td>35.785714</td>\n",
       "      <td>65.285714</td>\n",
       "      <td>46.857143</td>\n",
       "      <td>61.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>57.200000</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>54.066667</td>\n",
       "      <td>33.066667</td>\n",
       "      <td>57.266667</td>\n",
       "      <td>56.466667</td>\n",
       "      <td>55.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>55.133333</td>\n",
       "      <td>58.733333</td>\n",
       "      <td>38.533333</td>\n",
       "      <td>51.533333</td>\n",
       "      <td>63.200000</td>\n",
       "      <td>51.133333</td>\n",
       "      <td>33.533333</td>\n",
       "      <td>60.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>45.812500</td>\n",
       "      <td>72.562500</td>\n",
       "      <td>47.125000</td>\n",
       "      <td>30.937500</td>\n",
       "      <td>27.937500</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>38.625000</td>\n",
       "      <td>33.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>64.125000</td>\n",
       "      <td>19.937500</td>\n",
       "      <td>46.437500</td>\n",
       "      <td>41.562500</td>\n",
       "      <td>55.562500</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>40.687500</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>14.437500</td>\n",
       "      <td>54.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>40.071429</td>\n",
       "      <td>59.857143</td>\n",
       "      <td>44.571429</td>\n",
       "      <td>54.428571</td>\n",
       "      <td>35.071429</td>\n",
       "      <td>52.285714</td>\n",
       "      <td>48.571429</td>\n",
       "      <td>49.785714</td>\n",
       "      <td>...</td>\n",
       "      <td>51.428571</td>\n",
       "      <td>75.785714</td>\n",
       "      <td>47.071429</td>\n",
       "      <td>51.357143</td>\n",
       "      <td>49.142857</td>\n",
       "      <td>55.857143</td>\n",
       "      <td>38.071429</td>\n",
       "      <td>55.785714</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>46.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>42.117647</td>\n",
       "      <td>60.529412</td>\n",
       "      <td>53.823529</td>\n",
       "      <td>50.764706</td>\n",
       "      <td>35.705882</td>\n",
       "      <td>59.764706</td>\n",
       "      <td>49.764706</td>\n",
       "      <td>42.647059</td>\n",
       "      <td>...</td>\n",
       "      <td>54.176471</td>\n",
       "      <td>80.764706</td>\n",
       "      <td>47.823529</td>\n",
       "      <td>53.235294</td>\n",
       "      <td>57.352941</td>\n",
       "      <td>47.705882</td>\n",
       "      <td>35.823529</td>\n",
       "      <td>62.823529</td>\n",
       "      <td>29.294118</td>\n",
       "      <td>49.823529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker_ID speaker_gender  non_likable     secure  attractive  \\\n",
       "0           1         female    36.571429  65.214286   59.785714   \n",
       "1           2         female    66.666667  57.200000   39.333333   \n",
       "2           3         female    45.812500  72.562500   47.125000   \n",
       "3           4           male    40.071429  59.857143   44.571429   \n",
       "4           5           male    42.117647  60.529412   53.823529   \n",
       "\n",
       "   unsympathetic  indecisive  unobtrusive    distant      bored    ...      \\\n",
       "0      37.357143   33.714286    66.857143  35.642857  35.642857    ...       \n",
       "1      54.066667   33.066667    57.266667  56.466667  55.733333    ...       \n",
       "2      30.937500   27.937500    46.250000  38.625000  33.437500    ...       \n",
       "3      54.428571   35.071429    52.285714  48.571429  49.785714    ...       \n",
       "4      50.764706   35.705882    59.764706  49.764706  42.647059    ...       \n",
       "\n",
       "    friendly  masculine  submissive  indifferent  interesting    cynical  \\\n",
       "0  75.428571  20.285714   59.000000    34.571429    60.571429  43.071429   \n",
       "1  55.600000  18.333333   55.133333    58.733333    38.533333  51.533333   \n",
       "2  64.125000  19.937500   46.437500    41.562500    55.562500  50.250000   \n",
       "3  51.428571  75.785714   47.071429    51.357143    49.142857  55.857143   \n",
       "4  54.176471  80.764706   47.823529    53.235294    57.352941  47.705882   \n",
       "\n",
       "   artificial  intelligent   childish     modest  \n",
       "0   35.785714    65.285714  46.857143  61.071429  \n",
       "1   63.200000    51.133333  33.533333  60.266667  \n",
       "2   40.687500    60.250000  14.437500  54.812500  \n",
       "3   38.071429    55.785714  40.500000  46.928571  \n",
       "4   35.823529    62.823529  29.294118  49.823529  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load scores (averaged across listeners)\n",
    "\n",
    "path = \"https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/\"\n",
    "\n",
    "url = path + \"ratings_SC_means.csv\"\n",
    "s = requests.get(url).content\n",
    "ratings =pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "sc_names = list(ratings.drop(['speaker_ID','speaker_gender'], axis=1))\n",
    "\n",
    "ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test partitions\n",
    "\n",
    "# read partitions from multioutput multiclass classification\n",
    "# (stratified taking into account speaker gender)\n",
    "\n",
    "url = path + \"classes_train.csv\"\n",
    "s = requests.get(url).content\n",
    "classes_train =pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"classes_test.csv\"\n",
    "s = requests.get(url).content\n",
    "classes_test =pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "# partitions of ratings for regression\n",
    "ratings = ratings.rename(index=str, columns={'speaker_ID': 'spkID'})\n",
    "ratings_train = ratings[ratings['spkID'].isin(classes_train['spkID'])] # shape (225, 36)\n",
    "ratings_test = ratings[ratings['spkID'].isin(classes_test['spkID'])] # shape (75, 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech features\n",
    "\n",
    "Same features as for classification (of clean speech).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/extracted_features/\"\n",
    "\n",
    "url = path + \"/eGeMAPSv01a_semispontaneous_splitted.csv\"\n",
    "s = requests.get(url).content\n",
    "feats =pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ';') # shape: 3591, 89\n",
    "\n",
    "# extract speaker ID from speech file name\n",
    "feats['spkID'] = feats['name'].str.slice(2, 5).astype('int')\n",
    "\n",
    "# appending multilabels to features\n",
    "feats_ratings_train = pd.merge(feats, ratings_train) # shape (2700, 125)\n",
    "feats_ratings_test = pd.merge(feats, ratings_test) # shape (891, 125)\n",
    "\n",
    "# save to csv\n",
    "feats_ratings_train.to_csv(r'.\\data_while_tuning\\feats_ratings_train.csv', index=False)\n",
    "feats_ratings_test.to_csv(r'.\\data_while_tuning\\feats_ratings_test.csv', index=False)\n",
    "\n",
    "# save feature names\n",
    "dropcolumns = ['name','spkID','speaker_gender'] + sc_names\n",
    "feats_names = list(feats_ratings_train.drop(dropcolumns, axis=1))\n",
    "\n",
    "myfile = open(r'.\\data_while_tuning\\feats_names.csv', 'w')\n",
    "for item in feats_names:\n",
    "    myfile.write(\"%r\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize speech features  \n",
    "\n",
    "# learn transformation on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feats_ratings_train.drop(dropcolumns, axis=1))\n",
    "\n",
    "# numpy n_instances x n_feats\n",
    "feats_s_train = scaler.transform(feats_ratings_train.drop(dropcolumns, axis=1))\n",
    "feats_s_test = scaler.transform(feats_ratings_test.drop(dropcolumns, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning with feature selection\n",
    "\n",
    "As done for classification, I perform nested hyperparameter tuning with feature selection.\n",
    "\n",
    "* Feature selection: SelectKBest(f_regression), tuning k\n",
    "* RandomizedSearchCV on hyperparameters with uniform distribution, instead of grid search\n",
    "* metric: neg_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select a trait\n",
    "# perform this on a loop later\n",
    "target_trait = sc_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in A (hyperparameter tuning): 2160\n",
      "Number of instances in B (meta-evaluation): 540\n"
     ]
    }
   ],
   "source": [
    "X = feats_s_train # (2700, 88)\n",
    "y = feats_ratings_train[target_trait].as_matrix() # (2700,)\n",
    "\n",
    "Xt = feats_s_test # (891, 88)\n",
    "yt = feats_ratings_test[target_trait].as_matrix() # (891,)\n",
    "\n",
    "# split train data into 80% and 20% subsets - with balance in gender\n",
    "# give subset A to the inner hyperparameter tuner\n",
    "# and hold out subset B for meta-evaluation\n",
    "AX, BX, Ay, By = train_test_split(X, y, test_size=0.20, stratify = feats_ratings_train['speaker_gender'], random_state=2302)\n",
    "\n",
    "print('Number of instances in A (hyperparameter tuning):',AX.shape[0])\n",
    "print('Number of instances in B (meta-evaluation):',BX.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe with results from hp tuner to be appended\n",
    "tuning_all = pd.DataFrame()\n",
    "\n",
    "# list with tuned classifiers trained on training data, to be appended\n",
    "trained_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling hp_tuner() for each target and each regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recover ** when new ipynb session started.\n",
    "\n",
    "(Workaround for working with hyperparameter tuning during several days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original features and ratings\n",
    "feats_ratings_train = pd.read_csv(r'.\\data_while_tuning\\feats_ratings_train.csv')\n",
    "feats_ratings_test = pd.read_csv(r'.\\data_while_tuning\\feats_ratings_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading outpus of hp tuning from disk\n",
    "tuning_all, trained_all = load_tuning(target_trait)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this after each experiment **to recover later**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save tuning_all (.csv) and trained_all (nameclassifier.sav)\n",
    "save_tuning(tuning_all, trained_all, target_trait)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression\n",
    "\n",
    "*class sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)*\n",
    "\n",
    "Check performance with linear regression just as baseline.\n",
    "\n",
    "(Need to improve this by removing collinearity first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LinearRegression' -> Best cross-val score on A set: -79.288586 using {'selecter__k': 82}\n",
      "'LinearRegression' -> Selected features: ['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm', 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0', 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0', 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean', 'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0', 'loudness_sma3_percentile50.0', 'loudness_sma3_percentile80.0', 'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope', 'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope', 'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean', 'spectralFlux_sma3_stddevNorm', 'mfcc1_sma3_amean', 'mfcc1_sma3_stddevNorm', 'mfcc2_sma3_stddevNorm', 'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean', 'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean', 'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean', 'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean', 'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean', 'logRelF0-H1-H2_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean', 'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean', 'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean', 'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean', 'F1amplitudeLogRelF0_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean', 'F2bandwidth_sma3nz_amean', 'F2bandwidth_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean', 'F3bandwidth_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_amean', 'F3amplitudeLogRelF0_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_stddevNorm', 'hammarbergIndexV_sma3nz_amean', 'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean', 'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean', 'slopeV500-1500_sma3nz_stddevNorm', 'spectralFluxV_sma3nz_amean', 'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm', 'mfcc2V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean', 'mfcc3V_sma3nz_stddevNorm', 'mfcc4V_sma3nz_amean', 'mfcc4V_sma3nz_stddevNorm', 'alphaRatioUV_sma3nz_amean', 'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean', 'slopeUV500-1500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean', 'loudnessPeaksPerSec', 'VoicedSegmentsPerSec', 'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec', 'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength', 'equivalentSoundLevel_dBp']\n",
      "'LinearRegression' -> root mean_squared_error on B set: 9.157625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\"\n",
    "Linear Regression\n",
    "\"\"\"\n",
    "def get_LinearRegression2tune():\n",
    "\n",
    "    model = LinearRegression()\n",
    "    hp = dict()\n",
    "    return 'LinearRegression', model, hp\n",
    "\n",
    "# Hyperparameter tuning with this model\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, [get_LinearRegression2tune], feats_names)\n",
    "\n",
    "# update lists of tuning info and trained classifiers\n",
    "tuning_all = tuning_all.append(tuning, ignore_index=True)\n",
    "trained_all.append(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet Regression\n",
    "\n",
    "*class sklearn.linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection=’cyclic’)*\n",
    "\n",
    "Combines the properties of both Ridge Regression and LASSO regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ElasticNet' -> Best cross-val score on A set: -91.034971 using {'selecter__k': 82}\n",
      "'ElasticNet' -> Selected features: ['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm', 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0', 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0', 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean', 'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0', 'loudness_sma3_percentile50.0', 'loudness_sma3_percentile80.0', 'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope', 'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope', 'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean', 'spectralFlux_sma3_stddevNorm', 'mfcc1_sma3_amean', 'mfcc1_sma3_stddevNorm', 'mfcc2_sma3_stddevNorm', 'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean', 'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean', 'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean', 'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean', 'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean', 'logRelF0-H1-H2_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean', 'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean', 'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean', 'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean', 'F1amplitudeLogRelF0_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean', 'F2bandwidth_sma3nz_amean', 'F2bandwidth_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean', 'F3bandwidth_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_amean', 'F3amplitudeLogRelF0_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_stddevNorm', 'hammarbergIndexV_sma3nz_amean', 'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean', 'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean', 'slopeV500-1500_sma3nz_stddevNorm', 'spectralFluxV_sma3nz_amean', 'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm', 'mfcc2V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean', 'mfcc3V_sma3nz_stddevNorm', 'mfcc4V_sma3nz_amean', 'mfcc4V_sma3nz_stddevNorm', 'alphaRatioUV_sma3nz_amean', 'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean', 'slopeUV500-1500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean', 'loudnessPeaksPerSec', 'VoicedSegmentsPerSec', 'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec', 'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength', 'equivalentSoundLevel_dBp']\n",
      "'ElasticNet' -> root mean_squared_error on B set: 9.060913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\"\"\"\n",
    "ElasticNet Regression\n",
    "\"\"\"\n",
    "def get_ElasticNet2tune():\n",
    "\n",
    "    model = ElasticNet()\n",
    "    hp = dict()\n",
    "    return 'ElasticNet', model, hp\n",
    "\n",
    "# Hyperparameter tuning with this model\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, [get_ElasticNet2tune], feats_names)\n",
    "\n",
    "# update lists of tuning info and trained classifiers\n",
    "tuning_all = tuning_all.append(tuning, ignore_index=True)\n",
    "trained_all.append(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors\n",
    "\n",
    "*class sklearn.neighbors.KNeighborsRegressor(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=1, **kwargs)*\n",
    "\n",
    "Tuning number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'KNeighborsRegressor' -> Best cross-val score on A set: -49.500822 using {'selecter__k': 62, 'regressor__weights': 'uniform', 'regressor__n_neighbors': 4, 'regressor__algorithm': 'ball_tree'}\n",
      "'KNeighborsRegressor' -> Selected features: ['F0semitoneFrom27.5Hz_sma3nz_stddevNorm', 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0', 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0', 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope', 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean', 'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0', 'loudness_sma3_percentile50.0', 'loudness_sma3_meanRisingSlope', 'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope', 'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean', 'mfcc1_sma3_stddevNorm', 'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean', 'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean', 'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean', 'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean', 'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean', 'logRelF0-H1-A3_sma3nz_amean', 'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean', 'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean', 'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean', 'F2frequency_sma3nz_amean', 'F2bandwidth_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean', 'hammarbergIndexV_sma3nz_amean', 'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean', 'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean', 'spectralFluxV_sma3nz_amean', 'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean', 'mfcc4V_sma3nz_amean', 'alphaRatioUV_sma3nz_amean', 'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean', 'loudnessPeaksPerSec', 'VoicedSegmentsPerSec', 'MeanVoicedSegmentLengthSec', 'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength', 'equivalentSoundLevel_dBp']\n",
      "'KNeighborsRegressor' -> root mean_squared_error on B set: 6.517480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\"\"\"\n",
    "K Nearest Neighbors\n",
    "\"\"\"\n",
    "def get_KNeighborsRegressor2tune():\n",
    "\n",
    "    model = KNeighborsRegressor()\n",
    "    hp = dict(\n",
    "        regressor__n_neighbors = list(range(1,40)),\n",
    "        regressor__weights = ['uniform','distance'],\n",
    "        regressor__algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    )\n",
    "    return 'KNeighborsRegressor', model, hp\n",
    "\n",
    "# Hyperparameter tuning with this model\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, [get_KNeighborsRegressor2tune], feats_names)\n",
    "\n",
    "# update lists of tuning info and trained classifiers\n",
    "tuning_all = tuning_all.append(tuning, ignore_index=True)\n",
    "trained_all.append(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Adaptive Regression Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# neigh = KNeighborsRegressor(n_neighbors=11, weights = 'distance')\n",
    "# neigh.fit(X, y) \n",
    "\n",
    " \n",
    "# y_pred = neigh.predict(Xt) \n",
    "\n",
    "\n",
    "# # root mean squared error\n",
    "# myrmse = np.sqrt(mean_squared_error(yt, y_pred))\n",
    "# print(myrmse)\n",
    "\n",
    "# # median absolute percentage error \n",
    "# mymape = mape(yt, y_pred)\n",
    "# print(mymape)\n",
    "\n",
    "# # coefficient of determination R^2\n",
    "# R2 = r2_score(yt, y_pred)\n",
    "# print(R2)\n",
    "\n",
    "# score = neigh.score(Xt, yt)\n",
    "# print(score) # same as R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(targets, predictions):\n",
    "    return np.median(abs((targets - predictions)/targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
