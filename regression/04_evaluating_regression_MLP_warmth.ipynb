{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression techniques for speaker characterization\n",
    "### Laura Fern√°ndez Gallardo\n",
    "\n",
    "Like in Part 02, I will address the detection of warmth, this time trying with Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import time # for timestamps\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval # parsing hp after tuner\n",
    "\n",
    "from reg_tuning import * # my helper functions\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 2302\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/'\n",
    "\n",
    "url = path + \"feats_ratings_scores_train.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_train = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"feats_ratings_scores_test.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_test = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "with open(r'..\\data\\generated_data\\feats_names.txt') as f:\n",
    "    feats_names = f.readlines()\n",
    "feats_names = [x.strip().strip('\\'') for x in feats_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\items_names.txt') as f:\n",
    "    items_names = f.readlines()\n",
    "items_names = [x.strip().strip('\\'') for x in items_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\traits_names.txt') as f:\n",
    "    traits_names = f.readlines()\n",
    "traits_names = [x.strip().strip('\\'') for x in traits_names] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning with feature selection\n",
    "\n",
    "Multi-layer perceptron. Load same train/test splits as in Part II.\n",
    "\n",
    "* no feature selection\n",
    "* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize speech features  \n",
    "\n",
    "dropcolumns = ['name','spkID','speaker_gender'] + items_names + traits_names\n",
    "\n",
    "# learn transformation on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feats_ratings_scores_train.drop(dropcolumns, axis=1))\n",
    "\n",
    "# numpy n_instances x n_feats\n",
    "feats_s_train = scaler.transform(feats_ratings_scores_train.drop(dropcolumns, axis=1))\n",
    "feats_s_test = scaler.transform(feats_ratings_scores_test.drop(dropcolumns, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select a trait\n",
    "# perform this on a loop later\n",
    "target_trait = traits_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test partitions, features and labels\n",
    "X = np.load(r'.\\data_while_tuning\\X_' + target_trait + '.npy')\n",
    "y = np.load(r'.\\data_while_tuning\\y_' + target_trait + '.npy')\n",
    "Xt = np.load(r'.\\data_while_tuning\\Xt_' + target_trait + '.npy')\n",
    "yt = np.load(r'.\\data_while_tuning\\yt_' + target_trait + '.npy')\n",
    "\n",
    "# A/B splits, features and labels\n",
    "AX = np.load(r'.\\data_while_tuning\\AX_' + target_trait + '.npy')\n",
    "BX = np.load(r'.\\data_while_tuning\\BX_' + target_trait + '.npy')\n",
    "Ay = np.load(r'.\\data_while_tuning\\Ay_' + target_trait + '.npy')\n",
    "By = np.load(r'.\\data_while_tuning\\By_' + target_trait + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Neural Network Model\n",
    "\n",
    "* single fully connected hidden layer with the same number of neurons as input attributes (88)\n",
    "* relu activation function for the hidden layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\"\"\"\n",
    "MLP with KerasRegressor\n",
    "\"\"\"\n",
    "\n",
    "def create_model(optimizer = 'Adam', learn_rate=0.2, neurons=1, activation='relu', dropout_rate=0.0):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons,\n",
    "                    activation=activation, \n",
    "                    input_dim=88))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_KerasRegressor2tune():\n",
    "    \n",
    "    model = KerasRegressor(build_fn = create_model, verbose=0)\n",
    "                        \n",
    "    hp = dict(\n",
    "        regressor__epochs = [25,50,75,100],\n",
    "        regressor__batch_size = [5,10], \n",
    "        regressor__neurons = [40, 80, 160]#,\n",
    "        #regressor__learn_rate = [0.2], # np.arange(start=0.2, stop=1.0, step=0.05) \n",
    "        #regressor__activation = ['relu'], # ['softmax', 'softplus', 'sofsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "        #regressor__dropout_rate = [0.5], # np.arange(start=0, stop=1, step=0.1)\n",
    "        #regressor__optimizer = ['Adam'] #['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "    )\n",
    "    return 'KerasRegressor', model, hp\n",
    "\n",
    "\n",
    "# tune with poly kernel\n",
    "tuning, trained = hp_tuner(AX, BX, Ay, By, \n",
    "                           [get_KerasRegressor2tune], \n",
    "                           target_trait,\n",
    "                           feats_names,\n",
    "                           [88], \n",
    "                           'random',\n",
    "                           n_iter=2\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
