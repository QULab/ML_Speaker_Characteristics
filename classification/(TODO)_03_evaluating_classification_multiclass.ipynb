{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel binary classification of speaker traits\n",
    "### Laura FernÃ¡ndez Gallardo\n",
    "\n",
    "After evluating the binary classification of speakers' warmth-attractiveness (WAAT), I examine in this notebook multilabel classification, that is, predicting several traits attributed to speakers, which are not mutually exclusive.   \n",
    "\n",
    "* For each perceptive speaker interpersonal dimension generated from [factor analysis](https://github.com/laufergall/Subjective_Speaker_Characteristics/tree/master/speaker_characteristics/factor_analysis) thrsholding scores based on percentiles to define 3 classes (\"high\", \"mid\", and \"low\") with approximately the same number of samples. These dimensions are: *warmth*, *attractiveness*, *confidence*, *compliance*, and *maturity*.\n",
    "* Only the \"high\" and \"low\" classes are of interest -> I address **multilabel binary classification**.\n",
    "* As evaluation metric, I will consider the average per-class accuracy (average of sensitivity and specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/'\n",
    "\n",
    "url = path + \"feats_ratings_scores_train.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_train = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"feats_ratings_scores_test.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_ratings_scores_test = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "with open(r'..\\data\\generated_data\\feats_names.txt') as f:\n",
    "    feats_names = f.readlines()\n",
    "feats_names = [x.strip().strip('\\'') for x in feats_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\items_names.txt') as f:\n",
    "    items_names = f.readlines()\n",
    "items_names = [x.strip().strip('\\'') for x in items_names] \n",
    "\n",
    "with open(r'..\\data\\generated_data\\traits_names.txt') as f:\n",
    "    traits_names = f.readlines()\n",
    "traits_names = [x.strip().strip('\\'') for x in traits_names] \n",
    "\n",
    "# read speaker trait classes\n",
    "path2 = 'https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/generated_data/'\n",
    "\n",
    "url = path2 + \"classes_train.csv\"\n",
    "s = requests.get(url).content\n",
    "classes_train =pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path2 + \"classes_test.csv\"\n",
    "s = requests.get(url).content\n",
    "classes_test =pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending classes to features\n",
    "\n",
    "dropcolumns = ['name','speaker_gender'] + items_names + traits_names # 'spkID' in for the merge\n",
    "feats_train = feats_ratings_scores_train.drop(dropcolumns, axis=1) # shape (2700, 88)\n",
    "feats_test = feats_ratings_scores_test.drop(dropcolumns, axis=1) # shape (2700, 88)\n",
    "\n",
    "feats_class_train = pd.merge(feats_train, classes_train.drop(['sample_heard','gender',], axis=1)) # shape (2700, 94)\n",
    "feats_class_test = pd.merge(feats_test, classes_test.drop(['sample_heard','gender',], axis=1)) # shape (891, 94)\n",
    "\n",
    "# classes as categorical\n",
    "for col in traits_names:\n",
    "    feats_class_train[col]=feats_class_train[col].astype('category')\n",
    "    feats_class_test[col]=feats_class_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize speech features  \n",
    "\n",
    "dropcolumns2 = ['spkID'] + traits_names\n",
    "\n",
    "# learn transformation on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feats_class_train.drop(dropcolumns2, axis=1))\n",
    "\n",
    " \n",
    "# numpy n_instances x n_feats\n",
    "feats_s_train = scaler.transform(feats_class_train.drop(dropcolumns2, axis=1))\n",
    "feats_s_test = scaler.transform(feats_class_test.drop(dropcolumns2, axis=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model tuning with feature selection\n",
    "\n",
    "As done for classification, I perform nested hyperparameter tuning with feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quick working example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = feats_s_train\n",
    "Y = feats_class_train[dim_names].apply(lambda x: x.cat.codes).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = feats_s_test\n",
    "Yt = feats_class_test[dim_names].apply(lambda x: x.cat.codes).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 1, 1],\n",
       "       [1, 2, 0, 1, 1],\n",
       "       [1, 2, 0, 1, 1],\n",
       "       ..., \n",
       "       [2, 1, 2, 0, 2],\n",
       "       [2, 1, 2, 0, 2],\n",
       "       [2, 1, 2, 0, 2]], dtype=int8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 2, 2],\n",
       "       [2, 0, 0, 2, 2],\n",
       "       [0, 0, 0, 2, 2],\n",
       "       ..., \n",
       "       [1, 2, 1, 2, 2],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 2, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48466142910587351"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "score = hamming_score(Yt, Y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO:\n",
    "    \n",
    "* define performance metric\n",
    "* model tuning\n",
    "* try different classifiers\n",
    "    * Support multiclass-multioutput:\n",
    "sklearn.tree.DecisionTreeClassifier\n",
    "sklearn.tree.ExtraTreeClassifier\n",
    "sklearn.ensemble.ExtraTreesClassifier\n",
    "sklearn.neighbors.KNeighborsClassifier\n",
    "sklearn.neighbors.RadiusNeighborsClassifier\n",
    "sklearn.ensemble.RandomForestClassifier\n",
    "http://scikit-learn.org/stable/modules/multiclass.html\n",
    "    * try MLP multiclass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
