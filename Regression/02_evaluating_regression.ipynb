{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression techniques for speaker characterization - Part II\n",
    "### Laura FernÃ¡ndez Gallardo\n",
    "\n",
    "In this notebook, I will evaluate the performance of different regression techniques for characterizing the user, given the data explored in Part I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 2302\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load speech features from male and from female speakers\n",
    "\n",
    "path = \"https://raw.githubusercontent.com/laufergall/ML_Speaker_Characteristics/master/data/\"\n",
    "\n",
    "# load subjective questionnaire items and their translations\n",
    "url = path + \"eGeMAPSv01a_88_malespk.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_m =pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "url = path + \"eGeMAPSv01a_88_femalespk.csv\"\n",
    "s = requests.get(url).content\n",
    "feats_f =pd.read_csv(io.StringIO(s.decode('utf-8')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pre-processing features:\n",
    "\n",
    "* join males and females and add 1-hot encoded gender feature\n",
    "* center and scale speech features of all data\n",
    "\n",
    "Database partitions: consider train/dev partitions and cross-validation (no test data, since we have too few instances)\n",
    "\n",
    "Within each fold of the cross-validation:\n",
    "\n",
    "* Feature selection looking at importance measures - with cross-val (?)\n",
    "* Feature selection removing multicollinearity:\n",
    "\n",
    "    1. NO -> Performing PLS (partial least squares) - and the linear regression! :S\n",
    "    2. Performing PCA (principal component analysis)\n",
    "    3. Dropping features with high VIF (variance inflation factor) - to be calculated after train/dev/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all features: males and females\n",
    "feats_m['is_male']=1\n",
    "feats_f['is_male']=0\n",
    "feats = pd.concat([feats_m,feats_f], axis = 0)\n",
    "\n",
    "feats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract speaker ID from sample_heard\n",
    "\n",
    "feats['speaker_ID'] = feats['sample_heard'].str.slice(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize features  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feats.iloc[:,1:-2])\n",
    "feats_s = scaler.transform(feats.iloc[:,1:-2]) # numpy 300x88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA to reduce the number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(feats_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_pca = pca.transform(feats_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_pca.shape # np array 300 x n_pcacomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign instances into 3 classes (1: low, 2: mid, 3: high) for each trait.\n",
    "\n",
    "(To plot PCA components color-coded by speaker class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ratings (averaged across listeners)\n",
    "ratings_means = pd.read_csv(\"SC_ratings_means.csv\")\n",
    "\n",
    "ratings_class = pd.DataFrame(index = ratings_means.index, columns=ratings_means.columns)\n",
    "\n",
    "# for each trait, assign instances into 3 classes\n",
    "for i in ratings_means.columns[2:]:\n",
    "    # percentiles to threshold\n",
    "    th = np.percentile(ratings_means[i],[33,66])\n",
    "    ratings_class.loc[ratings_means[i]<th[0],i] = 1 # low class\n",
    "    ratings_class.loc[ratings_means[i]>=th[0],i] = 2 # mid class\n",
    "    ratings_class.loc[ratings_means[i]>th[1],i] = 3 # high class\n",
    "    \n",
    "ratings_class.iloc[:,0:2] = ratings_means.iloc[:,0:2]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first pca components\n",
    "\n",
    "feats_pca_pd = pd.DataFrame(feats_pca, columns = np.char.mod('%d', np.arange(88)))\n",
    "\n",
    "plt.scatter(x=\"0\", y=\"1\", data = feats_pca_pd, c=ratings_class['intelligent'])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by looking at the traits for which listeners had slightly higher agreement: \n",
    "\n",
    "* _intelligent_\n",
    "* _ugly_\n",
    "* _old_\n",
    "* _modest_\n",
    "* _incompetent_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross-validation to determine optimal number of components for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# focus on the traits with least stdev averaged over all speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
